---
title: Symbol Manipulation
date: '2015-12-12'
tags:
    - Philosophy
    - Theory of Mind
excerpt: The Chinese Room experiment places Searle inside a room, in which he receives inputs in Chinese and instructions on how to process those inputs in English furthermore Searle has no previous knowledge of Chinese or its grammatical structures. Suppose that Searle and the programmers who are giving him instructions get so good at their respective tasks that Searle’s Chinese outputs become indistinguishable from those of a native Chinese speaker.
layout: 'post'
---

The Chinese Room experiment places Searle inside a room, in which he
receives inputs in Chinese and instructions on how to process those
inputs in English furthermore Searle has no previous knowledge of
Chinese or its grammatical structures. Suppose that Searle and the
programmers who are giving him instructions get so good at their
respective tasks that Searle’s Chinese outputs become
indistinguishable from those of a native Chinese speaker.[^fn-searle]

Searle’s argument goes as follows:

1.	In the Chinese Room Experiment Searle uses the formal properties
      of symbols to produce output symbols, but this does not generate
      understanding.
2.	There is nothing more that a computer program has than what Searle
      has inside the room.
3.	So a computer program doesn’t understand what the symbols mean and
      therefore does not have a mind.

One would intuitively conclude that even though Searle can respond to
Chinese inputs, he has no idea of what those inputs are about or the
meaning of his response. This contradicts the Strong AI view that a
machine can be said to literally understand the content it is
manipulating, rather according to Searle it is only manipulating
symbols. As a human can carry out any computer function without being
said to understand the content, the machine can therefore not
understand and is not a mind.

## We're all symbol manipulators!

The first objection to Searle’s Argument is from Robert Abelson, who’s
response is titled “Searle’s argument is just a set of Chinese
symbols”[^fn-abelson], I have to agree with Abelson, we express the
vast majority of our thoughts to the world through the manipulation of
formal symbols, both in Speech and Writing. For the most part we
accept the symbolic and formal definitions of objects in our world and
interact with them in a symbolic manner. Take people with a
fundamental understanding of Mathematics, such people understand that
the symbols “1 + 1” equals the symbol “2”, but very few people know
why this is the case, and even fewer are able to prove that it is
so. These people are still said to understand basic mathematics, but
if Searle was correct they would be said to not really understand, but
are rather playing a game of symbol manipulation. As Abelson puts it
“We might be humble and give the computer the benefit of the doubt
when it performs as well as we do.”

Additionally this does not mean that the necessarily machine
understands as we do, but rather that there are situations in which
our understanding and a machines symbol manipulation are carried out
through the same formal process. And for that reason we ought to give
them the benefit of the doubt, and to not assume that there is a
significant difference if the same process is occurring.

## Logical Connectives

In order for a mind to work, either formally or in a manner that ours
does, logical connectives are essential. In fact it is this tipping
stone that determines what a mind is. Searle states that
intentionality is the key factor and that machines only have
intentionality in virtue of their use case. (Searle, 1980, p. 419)
However we must examine the root of understanding in order to
determine that what it means to be a mind resides in a much more
fundamental process. Take for example Lewis Carroll’s “What the
Tortoise Said to Achilles”[^fn-carrol], in which a tortoise presents
the following argument:

>A: "Things that are equal to the same are equal to each other”

>B: "The two sides of this triangle are things that are equal to the
>same"

>Therefore Z: "The two sides of this triangle are equal to each other"

The tortoise then asks Achilles if the conclusion logically follows
from the premises, Achilles agrees. The tortoise then asks if a reader
could reject the premises, Achilles says yes, such a reader could
exist. The tortoise asks Achilles if a reader might accept both the
premises and but reject the conclusion. Achilles says such a reader
might exist, and the tortoise asks Achilles to prove the argument
valid to such a reader. Achilles then adds the premise,

>C: “If A and B are true, then Z must be true”.

The tortoise agrees to this new premise but still rejects the
conclusion. Such a reader could never be convinced of the argument, as
Achilles only recourse is to continue to add premises, which will have
no effect.

This ability to make logical leaps is key, as a system can just as
easily reject all aspects of an argument or system
altogether. Intelligence comes for a unique ability to reason about
inputs and logically determine the proper output.  This ability to
make logical connectives is essential in a minds operation, and
furthermore this characteristic is integrated at the physical level
(in the form of logic gates), so it can be said that computers
physically understand the logical connectives just as we physically
understand our senses on a physical level. This also divorces content
from the Boolean aspects of that content, it does not matter if the
subject matter is well know, but purely the ability to reason about
it. This is a much better way to determine a mind, as opposed to
Searle’s intentionality, which is unknown if we even have original
intentionality, and this question is inherently unresolvable. A
logical connective criteria therefore makes much more logical sense,
and also is something that can be worked towards, which unfortunately
original intentionality cannot.

## Some Possible Objections

*In response to the first objection mentioned to Searle’s Chinese
Room, one might argue that it does not matter than machines and humans
both sometimes operate in formal manners, as Humans have a possibility
of going further, into the realm of true knowledge as opposed to only
looking at formal symbols.*

To rephrase this view, if a human only operates formally, but the
potential of understanding exists then it is a mind. In order to know
that potential exists, the mind must actualize on that potential, and
therefore a mind is any thing that shows true understanding in any
domain, and the amount of understanding or range of understanding is
irrelevant. Therefore Logical connectives fit this description as
outlined above, and allows for true understanding of one domain, which
satisfied the potential of true understanding in the nature of the
machine itself.

---

*Just because logical connectives are more fundamental does not mean
that they are necessarily the tipping point in determining a mind.*

This objective misses the point with logical connectives. It is
impossible for a system to understand content without understanding a
logical connective. In order to understand a systems place in the
world, one must understand if I push the block, then the block will
move. Or that the sky is blue, and the sky is above me. Without such
abilities the world is a stream of inputs that make no sense, and
cannot be structured to uncover any truth in the world. In order to at
a very basic level, make sense of inputs and develop core logical
connectives are needed. Luckily they are the one things computers can
be said to truly understand in virtue their physical nature.

### References
[^fn-searle]: Searle, John R. (1980), ["Minds, brains, and programs"](http://papers.devinmcgloin.com/machine_minds/Searle%20_1980_%20Minds,%20Brains,%20and%20Programs.pdf), *Society for Philosophy and Psychology*
[^fn-carrol]: Carroll, Lewis (1995), [What the Tourtise said to Achilles](http://papers.devinmcgloin.com/machine_minds/achilles.pdf), *Mind*
[^fn-abelson]: Abelson, Robert (1980), ["Searle's argument is just a set of Chinese symbols"](http://papers.devinmcgloin.com/machine_minds/Searle%20_1980_%20Minds,%20Brains,%20and%20Programs.pdf), Page 424, *Society for Philosophy and Psychology*
