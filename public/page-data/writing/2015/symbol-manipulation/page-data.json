{"componentChunkName":"component---src-templates-writing-js","path":"/writing/2015/symbol-manipulation/","result":{"data":{"mdx":{"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Symbol Manipulation\",\n  \"date\": \"2015-12-12\",\n  \"tags\": [\"Philosophy\"],\n  \"excerpt\": \"The Chinese Room experiment places Searle inside a room, in which he receives inputs in Chinese and instructions on how to process those inputs in English furthermore Searle has no previous knowledge of Chinese or its grammatical structures. Suppose that Searle and the programmers who are giving him instructions get so good at their respective tasks that Searle’s Chinese outputs become indistinguishable from those of a native Chinese speaker.\",\n  \"layout\": \"post\"\n};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"The Chinese Room experiment places Searle inside a room, in which he\\nreceives inputs in Chinese and instructions on how to process those\\ninputs in English furthermore Searle has no previous knowledge of\\nChinese or its grammatical structures. Suppose that Searle and the\\nprogrammers who are giving him instructions get so good at their\\nrespective tasks that Searle\\u2019s Chinese outputs become\\nindistinguishable from those of a native Chinese speaker.\", mdx(\"sup\", _extends({\n    parentName: \"p\"\n  }, {\n    \"id\": \"fnref-1\"\n  }), mdx(\"a\", _extends({\n    parentName: \"sup\"\n  }, {\n    \"href\": \"#fn-1\",\n    \"className\": \"footnote-ref\"\n  }), \"1\"))), mdx(\"p\", null, \"Searle\\u2019s argument goes as follows:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"In the Chinese Room Experiment Searle uses the formal properties\\nof symbols to produce output symbols, but this does not generate\\nunderstanding.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"There is nothing more that a computer program has than what Searle\\nhas inside the room.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"So a computer program doesn\\u2019t understand what the symbols mean and\\ntherefore does not have a mind.\")), mdx(\"p\", null, \"One would intuitively conclude that even though Searle can respond to\\nChinese inputs, he has no idea of what those inputs are about or the\\nmeaning of his response. This contradicts the Strong AI view that a\\nmachine can be said to literally understand the content it is\\nmanipulating, rather according to Searle it is only manipulating\\nsymbols. As a human can carry out any computer function without being\\nsaid to understand the content, the machine can therefore not\\nunderstand and is not a mind.\"), mdx(\"h2\", null, \"We're all symbol manipulators!\"), mdx(\"p\", null, \"The first objection to Searle\\u2019s Argument is from Robert Abelson, who\\u2019s\\nresponse is titled \\u201CSearle\\u2019s argument is just a set of Chinese\\nsymbols\\u201D\", mdx(\"sup\", _extends({\n    parentName: \"p\"\n  }, {\n    \"id\": \"fnref-3\"\n  }), mdx(\"a\", _extends({\n    parentName: \"sup\"\n  }, {\n    \"href\": \"#fn-3\",\n    \"className\": \"footnote-ref\"\n  }), \"3\")), \", I have to agree with Abelson, we express the\\nvast majority of our thoughts to the world through the manipulation of\\nformal symbols, both in Speech and Writing. For the most part we\\naccept the symbolic and formal definitions of objects in our world and\\ninteract with them in a symbolic manner. Take people with a\\nfundamental understanding of Mathematics, such people understand that\\nthe symbols \\u201C1 + 1\\u201D equals the symbol \\u201C2\\u201D, but very few people know\\nwhy this is the case, and even fewer are able to prove that it is\\nso. These people are still said to understand basic mathematics, but\\nif Searle was correct they would be said to not really understand, but\\nare rather playing a game of symbol manipulation. As Abelson puts it\\n\\u201CWe might be humble and give the computer the benefit of the doubt\\nwhen it performs as well as we do.\\u201D\"), mdx(\"p\", null, \"Additionally this does not mean that the necessarily machine\\nunderstands as we do, but rather that there are situations in which\\nour understanding and a machines symbol manipulation are carried out\\nthrough the same formal process. And for that reason we ought to give\\nthem the benefit of the doubt, and to not assume that there is a\\nsignificant difference if the same process is occurring.\"), mdx(\"h2\", null, \"Logical Connectives\"), mdx(\"p\", null, \"In order for a mind to work, either formally or in a manner that ours\\ndoes, logical connectives are essential. In fact it is this tipping\\nstone that determines what a mind is. Searle states that\\nintentionality is the key factor and that machines only have\\nintentionality in virtue of their use case. (Searle, 1980, p. 419)\\nHowever we must examine the root of understanding in order to\\ndetermine that what it means to be a mind resides in a much more\\nfundamental process. Take for example Lewis Carroll\\u2019s \\u201CWhat the\\nTortoise Said to Achilles\\u201D\", mdx(\"sup\", _extends({\n    parentName: \"p\"\n  }, {\n    \"id\": \"fnref-2\"\n  }), mdx(\"a\", _extends({\n    parentName: \"sup\"\n  }, {\n    \"href\": \"#fn-2\",\n    \"className\": \"footnote-ref\"\n  }), \"2\")), \", in which a tortoise presents\\nthe following argument:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"A: \\\"Things that are equal to the same are equal to each other\\u201D\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"B: \\\"The two sides of this triangle are things that are equal to the same\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Therefore Z: \\\"The two sides of this triangle are equal to each other\\\"\")), mdx(\"p\", null, \"The tortoise then asks Achilles if the conclusion logically follows\\nfrom the premises, Achilles agrees. The tortoise then asks if a reader\\ncould reject the premises, Achilles says yes, such a reader could\\nexist. The tortoise asks Achilles if a reader might accept both the\\npremises and but reject the conclusion. Achilles says such a reader\\nmight exist, and the tortoise asks Achilles to prove the argument\\nvalid to such a reader. Achilles then adds the premise,\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"C: \\u201CIf A and B are true, then Z must be true\\u201D.\")), mdx(\"p\", null, \"The tortoise agrees to this new premise but still rejects the\\nconclusion. Such a reader could never be convinced of the argument, as\\nAchilles only recourse is to continue to add premises, which will have\\nno effect.\"), mdx(\"p\", null, \"This ability to make logical leaps is key, as a system can just as\\neasily reject all aspects of an argument or system\\naltogether. Intelligence comes for a unique ability to reason about\\ninputs and logically determine the proper output. This ability to\\nmake logical connectives is essential in a minds operation, and\\nfurthermore this characteristic is integrated at the physical level\\n(in the form of logic gates), so it can be said that computers\\nphysically understand the logical connectives just as we physically\\nunderstand our senses on a physical level. This also divorces content\\nfrom the Boolean aspects of that content, it does not matter if the\\nsubject matter is well know, but purely the ability to reason about\\nit. This is a much better way to determine a mind, as opposed to\\nSearle\\u2019s intentionality, which is unknown if we even have original\\nintentionality, and this question is inherently unresolvable. A\\nlogical connective criteria therefore makes much more logical sense,\\nand also is something that can be worked towards, which unfortunately\\noriginal intentionality cannot.\"), mdx(\"h2\", null, \"Some Possible Objections\"), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"In response to the first objection mentioned to Searle\\u2019s Chinese\\nRoom, one might argue that it does not matter than machines and humans\\nboth sometimes operate in formal manners, as Humans have a possibility\\nof going further, into the realm of true knowledge as opposed to only\\nlooking at formal symbols.\")), mdx(\"p\", null, \"To rephrase this view, if a human only operates formally, but the\\npotential of understanding exists then it is a mind. In order to know\\nthat potential exists, the mind must actualize on that potential, and\\ntherefore a mind is any thing that shows true understanding in any\\ndomain, and the amount of understanding or range of understanding is\\nirrelevant. Therefore Logical connectives fit this description as\\noutlined above, and allows for true understanding of one domain, which\\nsatisfied the potential of true understanding in the nature of the\\nmachine itself.\"), mdx(\"hr\", null), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Just because logical connectives are more fundamental does not mean\\nthat they are necessarily the tipping point in determining a mind.\")), mdx(\"p\", null, \"This objective misses the point with logical connectives. It is\\nimpossible for a system to understand content without understanding a\\nlogical connective. In order to understand a systems place in the\\nworld, one must understand if I push the block, then the block will\\nmove. Or that the sky is blue, and the sky is above me. Without such\\nabilities the world is a stream of inputs that make no sense, and\\ncannot be structured to uncover any truth in the world. In order to at\\na very basic level, make sense of inputs and develop core logical\\nconnectives are needed. Luckily they are the one things computers can\\nbe said to truly understand in virtue their physical nature.\"), mdx(\"h3\", null, \"References\"), mdx(\"div\", {\n    \"className\": \"footnotes\"\n  }, mdx(\"hr\", {\n    parentName: \"div\"\n  }), mdx(\"ol\", {\n    parentName: \"div\"\n  }, mdx(\"li\", _extends({\n    parentName: \"ol\"\n  }, {\n    \"id\": \"fn-1\"\n  }), \"Searle, John R. (1980), \", mdx(\"a\", _extends({\n    parentName: \"li\"\n  }, {\n    \"href\": \"http://papers.devinmcgloin.com/machine_minds/Searle%20_1980_%20Minds,%20Brains,%20and%20Programs.pdf\"\n  }), \"\\\"Minds, brains, and programs\\\"\"), \", \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"Society for Philosophy and Psychology\"), mdx(\"a\", _extends({\n    parentName: \"li\"\n  }, {\n    \"href\": \"#fnref-1\",\n    \"className\": \"footnote-backref\"\n  }), \"\\u21A9\")), mdx(\"li\", _extends({\n    parentName: \"ol\"\n  }, {\n    \"id\": \"fn-3\"\n  }), \"Abelson, Robert (1980), \", mdx(\"a\", _extends({\n    parentName: \"li\"\n  }, {\n    \"href\": \"http://papers.devinmcgloin.com/machine_minds/Searle%20_1980_%20Minds,%20Brains,%20and%20Programs.pdf\"\n  }), \"\\\"Searle's argument is just a set of Chinese symbols\\\"\"), \", Page 424, \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"Society for Philosophy and Psychology\"), mdx(\"a\", _extends({\n    parentName: \"li\"\n  }, {\n    \"href\": \"#fnref-3\",\n    \"className\": \"footnote-backref\"\n  }), \"\\u21A9\")), mdx(\"li\", _extends({\n    parentName: \"ol\"\n  }, {\n    \"id\": \"fn-2\"\n  }), \"Carroll, Lewis (1995), \", mdx(\"a\", _extends({\n    parentName: \"li\"\n  }, {\n    \"href\": \"http://papers.devinmcgloin.com/machine_minds/achilles.pdf\"\n  }), \"What the Tourtise said to Achilles\"), \", \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"Mind\"), mdx(\"a\", _extends({\n    parentName: \"li\"\n  }, {\n    \"href\": \"#fnref-2\",\n    \"className\": \"footnote-backref\"\n  }), \"\\u21A9\")))));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"title":"Symbol Manipulation","date":"Saturday, December 12th 02015","tags":["Philosophy"]},"excerpt":"The Chinese Room experiment places Searle inside a room, in which he receives inputs in Chinese and instructions on how to process those inputs in English furthermore Searle has no previous knowledge of Chinese or its grammatical structures. Suppose that Searle and the programmers who are giving him instructions get so good at their respective tasks that Searle’s Chinese outputs become indistinguishable from those of a native Chinese speaker."}},"pageContext":{"slug":"/writing/2015/symbol-manipulation/"}}}